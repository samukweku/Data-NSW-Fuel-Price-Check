{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull the contents of the website\n",
    "r=requests.get('https://data.nsw.gov.au/data/dataset/fuel-check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.status_code #200 means download was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#tried lxml, it failed\n",
    "soup=BeautifulSoup(r.content,\"html.parser\")\n",
    "#transfer content into beautifulsoup, so i can filter what i want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/35416575/get-the-href-text-of-a-link-that-has-a-certain-class-attribute-using-beautifulso\n",
    "a=soup.find_all('a', {'class':\"resource-url-analytics\",'href':True})\n",
    "#looked at the website, and knew exactly where my data was..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this loops through and appends all the files to be downloaded\n",
    "b=[]\n",
    "for i in a:\n",
    "    b.append(i['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#strips out url that does not end with .xlsx\n",
    "b=[j for j in b if j.endswith('.xlsx')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=pd.Series(data=b) #create a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#redundancy \n",
    "z.to_csv('/home/sam/Github Folder/FuelCheck/fuelcheckurllist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary of months and abbreviations, which comes in handy\n",
    "#in the next cell... if there are any abbreviations of the month,\n",
    "#they will be replaced by the full month name.\n",
    "m_dict={'jan':'january','feb':'february', 'mar':'march','apr':'april',\\\n",
    "        'jun':'jun','jul':'july','aug':'august','sep':'september',\\\n",
    "         'oct':'october','nov':'november','dec':'december'}\n",
    "\n",
    "#declare an empty list variable\n",
    "url_m_y=[]\n",
    "for j in b:\n",
    "#split the string based on '/', strip the end of the '.xlsx'\n",
    "#and pull out the last string/word at the end using index notation [-1]\n",
    "    m_y_extract=j.split('/')[-1].rstrip('.xlsx')\n",
    "#some have '-' present, others do not. So I have to treat the extraction\n",
    "#differently.\n",
    "#i used [-7:], since the year is four digits and abbreviation is usually\n",
    "#three. so the '-' be before the year. \n",
    "#thinking about it, i could have made it [-6:]...yeah yeah.\n",
    "    if '-' in m_y_extract[-7:]:\n",
    "#i first split by '-', then slice it to get the month and year,\n",
    "#join it with '-' and add '.csv' at the end\n",
    "        m_y='-'.join(m_y_extract.split('-')[-2:])+'.csv'\n",
    "    if '-' not in m_y_extract[-7:]:\n",
    "#'-' not present, so a different procedure\n",
    "#extract the text before the year (the abbreviations are three digits)\n",
    "        p=m_y_extract[-7:][:3]\n",
    "#extract the year\n",
    "        q=m_y_extract[-7:][3:]\n",
    "#add them back with the '.csv'\n",
    "        m_y=p+'-'+q+'.csv'\n",
    "#now the dictionary comes into play\n",
    "#apparently abbreviations are present, and I need the full names of the\n",
    "#months for further work down.\n",
    "#I split 'm_y' into month and year\n",
    "    m=m_y.split('-')[0]\n",
    "    y=m_y.split('-')[-1]\n",
    "#I check if the abbreviation is present, and replace it with the full\n",
    "#month name.\n",
    "    if m in m_dict.keys():\n",
    "        m_y=m_dict[m]+'-'+y\n",
    "    url_m_y.append(m_y)\n",
    "        \n",
    "\n",
    "#create a dataframe of the url and month_year\n",
    "#comes in handy during the filter phase to determine which datasets \n",
    "#are already present, and which to download\n",
    "df_url=pd.DataFrame({'urllist':b,'url_month_year':url_m_y})\n",
    "\n",
    "#this pulls out the files in a directory...\n",
    "#the s.lower() converts to lowercase, so the work in the next cell\n",
    "#wont have any case (capital vs small letters) issues\n",
    "fuelcheck_filelist=[s.lower() for s in os.listdir('/home/sam/Github Folder/FuelCheck')]\n",
    "\n",
    "#using set notation, i find out which files have not been downloaded\n",
    "fuel_list_to_download=set(url_m_y)-set(fuelcheck_filelist)\n",
    "fuel_list_to_download=list(fuel_list_to_download)\n",
    "fuel_list_to_download\n",
    "\n",
    "#https://stackoverflow.com/questions/17071871/select-rows-from-a-dataframe-based-on-values-in-a-column-in-pandas\n",
    "#i then pass the filter above into the dataframe created\n",
    "url_listt=df_url[df_url['url_month_year'].isin(fuel_list_to_download)]['urllist'].tolist()\n",
    "\n",
    "#now i can download the specific files, and avoid downloading files\n",
    "#that already exist in my local folder.\n",
    "#i also convert to csv as it is much faster to process than .xlsx\n",
    "for i in url_listt:\n",
    "    file_download=pd.read_excel(i)\n",
    "    if file_download.columns[6] !='PriceUpdatedDate':\n",
    "        file_download.columns=file_download.iloc[0]\n",
    "        file_download=file_download.drop(index=0)\n",
    "        file_download=file_download.reset_index(drop=True)\n",
    "    file_name=file_download['PriceUpdatedDate'][0].strftime(\"%B-%Y\")\n",
    "    file_download.to_csv(('/home/Github Folder/FuelCheck/{}.csv').format(file_name))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
